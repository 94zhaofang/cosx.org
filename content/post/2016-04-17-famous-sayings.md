---
title: COS每周精选：名家名言
date: '2016-04-17T21:03:44+00:00'
author: COS编辑部
categories:
  - 每周精选
  - 统计之都
tags:
  - Feather包
  - 每周精选
slug: famous-sayings
---

本期投稿：朱雪宁  <a href="http://weibo.com/u/1657470871?from=feed&loc=avatar" target="_blank">王威廉 </a>  王小宁            编辑：王小宁

**名家名言**

王汉生：<a href="http://mp.weixin.qq.com/s?__biz=MzI4NzE4NzAxMg==&mid=2650285035&idx=1&sn=8da6ead967cdbd05ba7a83fb3376e504&3rd=MzA3MDU4NTYzMw==&scene=6#rd" target="_blank">传统制造业才是大数据的金矿</a>

**R 包**

突破数据框读写瓶颈，又一个造轮子的工作，<a href="https://blog.rstudio.org/2016/03/29/feather/" target="_blank"> Feather包</a>值得一试。

**行业应用**

Airbnb使用<a href="https://medium.com/airbnb-engineering/using-r-packages-and-education-to-scale-data-science-at-airbnb-906faa58e12d#.k9o4q7q98" target="_blank">Ｒ做数据分析</a>。<!--more-->

**学习材料**

剑桥大学信息论大神David MacKay在网上公开了他所讲授的16课时的《信息论、模式识别与神经网络》入门课程。看了一下，个人感觉David的入门课讲得算是出神入化，有很多很形象的例子，没有满屏幕的数学公式，可以让没有任何机器学习和信息论背景的人都能看懂。<a href="http://videolectures.net/course_information_theory_pattern_recognition/" target="_blank">视频链接</a>。

特征学习和深度学习热门会议( International Conference on Learning Representations (ICLR2016) 的两篇最佳论文。<a href="http://arxiv.org/abs/1511.06279" target="_blank">Neural Programmer-Interpreters</a>  和 <a href="http://arxiv.org/abs/1510.00149" target="_blank">Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding</a>。
